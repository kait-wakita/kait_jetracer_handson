{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習状況のチェック (mp4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "走行動画を用いて推論の結果を表示する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = 'off001'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'slowdrive'\n",
    "\n",
    "input_video = 'movie/' + TARGET + '.mp4'\n",
    "output_video = 'log/'  + TARGET + '_result.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "MODEL = TASK+\"_model.pth\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "    \n",
    "device = torch.device(DEVICE)\n",
    "output_dim = 2\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Linear(512, output_dim)\n",
    "\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('data/'+TASK+'_A/'+MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "if DEVICE== 'cuda':\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "    std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "else:\n",
    "    mean = torch.Tensor([0.485, 0.456, 0.406]).cpu()\n",
    "    std = torch.Tensor([0.229, 0.224, 0.225]).cpu()   \n",
    "\n",
    "\n",
    "def preprocess(image):\n",
    "    device = torch.device(DEVICE)\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                         # openCV\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import re\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Textarea,Layout\n",
    "\n",
    "IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 224\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(input_video) # 引数がファイルパス\n",
    "\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH)) # 動画の画面横幅\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)) # 動画の画面縦幅\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT)) # 総フレーム数\n",
    "frame_rate = int(video.get(cv2.CAP_PROP_FPS)) # フレームレート(fps)\n",
    "frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "fmt = cv2.VideoWriter_fourcc('m', 'p', '4', 'v') # ファイル形式(ここではmp4)\n",
    "writer = cv2.VideoWriter(output_video, fmt, frame_rate, (IMG_WIDTH,IMG_HEIGHT))  # 射影変換後の画像サイズ\n",
    "\n",
    "print('start processing ', input_video,' ...')\n",
    "for i in range(frame_count):\n",
    "    ret,img_tmp = video.read()\n",
    "    img = cv2.resize(img_tmp, dsize=(224,224))\n",
    "        \n",
    "    preprocessed = preprocess(img)\n",
    "    output = model(preprocessed).detach().cpu().numpy().flatten()\n",
    "    result_x = output[0]\n",
    "    result_y = output[1]\n",
    "    result_x = int(IMG_WIDTH * (result_x / 2.0 + 0.5))\n",
    "    result_y = int(IMG_HEIGHT * (result_y / 2.0 + 0.5))\n",
    "    \n",
    "    img = cv2.line(img,(112,0),(112,224),(255,255,255),3)\n",
    "    img = cv2.line(img,( 77,0),( 77,224),(255,255,255),1)\n",
    "    img = cv2.line(img,( 42,0),( 42,224),(255,255,255),1)\n",
    "    img = cv2.line(img,(147,0),(147,224),(255,255,255),1)\n",
    "    img = cv2.line(img,(182,0),(182,224),(255,255,255),1)\n",
    "    img = cv2.line(img,(0, 75),(224, 75),(255,255,255),1)\n",
    "    img = cv2.line(img,(0,112),(224,112),(255,255,255),1)\n",
    "    img = cv2.line(img,(0,150),(224,150),(255,255,255),1)\n",
    "    \n",
    "    image = cv2.circle(img, (result_x,result_y), 10, (0, 0, 255),3)\n",
    "    writer.write(image)\n",
    "    \n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)    \n",
    "    #plt.imshow(image)\n",
    "    #plt.show()\n",
    "\n",
    "video.release()\n",
    "writer.release() \n",
    "\n",
    "print('result file:', output_video)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
